{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"RtnzQPTVe7Ay"},"source":["# Project Overview\n","\n","![detecting.png](attachment:detecting.png)"]},{"cell_type":"markdown","metadata":{"id":"PWUC-8vze7A5"},"source":["# The Dataset\n","\n","The dataset consisted of 1376 images, 690 face images with masks and 686 without masks. The original dataset is prepared by [Prajna Bhandary](https://www.linkedin.com/in/prajna-bhandary-0b03a416a/) and available at [Github](https://github.com/prajnasb/observations/tree/master/experiements/data)\n","\n","![dataset.png](attachment:dataset.png)"]},{"cell_type":"markdown","metadata":{"id":"Zbg22_SAe7A6"},"source":["# Data Preprocessing\n","![pre.png](attachment:pre.png)"]},{"cell_type":"code","metadata":{"id":"qhjslJjIe7A7","outputId":"9f67618a-dad5-4eeb-b37d-00b3e039a8aa","executionInfo":{"status":"error","timestamp":1683109417846,"user_tz":-330,"elapsed":728,"user":{"displayName":"Debangshu Banik","userId":"15625339098002480905"}},"colab":{"base_uri":"https://localhost:8080/","height":237}},"source":["import cv2,os\n","\n","data_path='dataset'\n","categories=os.listdir(data_path)   \n","labels=[i for i in range(len(categories))]  # labels=[0, 1]\n","\n","label_dict=dict(zip(categories,labels))  #{'with mask':0,'without mask':1}\n","\n","print(label_dict)\n","print(categories)\n","print(labels)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-23d179391b25>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# labels=[0, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset'"]}]},{"cell_type":"code","metadata":{"id":"2F-HVDYVe7A-","executionInfo":{"status":"error","timestamp":1682856104384,"user_tz":-330,"elapsed":7,"user":{"displayName":"Ridha KP","userId":"17895640857396672329"}},"outputId":"58470d54-1412-4048-ac21-e0c849f6f9f1","colab":{"base_uri":"https://localhost:8080/","height":235}},"source":["img_size=100\n","data=[]\n","target=[]\n","\n","\n","for category in categories:\n","    folder_path=os.path.join(data_path,category)\n","    img_names=os.listdir(folder_path)  \n","        \n","    for img_name in img_names:\n","        img_path=os.path.join(folder_path,img_name)\n","        img=cv2.imread(img_path)\n","\n","        try:\n","            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)           \n","            #Coverting the image into gray scale\n","            resized=cv2.resize(gray,(img_size,img_size))\n","            #resizing the gray scale into 100x100, since we need a fixed common size for all the images in the dataset\n","            data.append(resized)\n","            target.append(label_dict[category])\n","            #appending the image and the label(categorized) into the list (dataset)\n","\n","        except Exception as e:\n","            print('Exception:',e)\n","            #if any exception rasied, the exception will be printed here. And pass to the next image"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-1d250783e004>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfolder_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'categories' is not defined"]}]},{"cell_type":"code","metadata":{"id":"sPaBI1XKe7BA"},"source":["import numpy as np\n","\n","data=np.array(data)/255.0 #normalistion\n","data=np.reshape(data,(data.shape[0],img_size,img_size,1))\n","target=np.array(target)\n","\n","from keras.utils import np_utils\n","\n","new_target=np_utils.to_categorical(target)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EMAj7EYne7BA"},"source":["np.save('data',data)\n","np.save('target',new_target)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yy8PXxqle7BB"},"source":[],"execution_count":null,"outputs":[]}]}